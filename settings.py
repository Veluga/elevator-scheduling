# Simulation config
TICK_LENGTH_IN_SECONDS = 1
AVERAGE_CALL_FREQUENCY = 5
EPISODE_LENGTH = 3600
RANDOM_SEED = 0xDEADBEEF
REWARD_DELIVERED_PASSENGER = 2

# Building config
NUM_FLOORS = 10
NUM_ELEVATORS = 4
FLOOR_HEIGHT = 4.0

# Non-TF Agent config
EPSILON = 0.05
STEP_SIZE = 0.1
DISCOUNT_RATE = 0.99

# Elevator config
MAX_VELOCITY=3.0
ACCELERATION=1.0
FLOOR_TIME=2
STOP_TIME=7
TURN_TIME=1

# Tensorflow config
NUM_ITERATIONS = 100000000
INTIIAL_COLLECT_STEPS = 5000
COLLECT_STEPS_PER_ITERATION = 1
REPLAY_BUFFER_MAX_LENGTH = 100000
BATCH_SIZE = 64
LEARNING_RATE = 1e-3
LOG_INTERVAL = 5000
NUM_EVAL_EPISODES = 1
EVAL_INTERVAL = 25000
FC_LAYER_PARAMS = (100, 100)
POLICY_SAVER_INTERVAL = EVAL_INTERVAL

# Categorical DQN Agent config
NUM_ATOMS = 51
MIN_Q_VALUE = 0
MAX_Q_VALUE = NUM_ELEVATORS * REWARD_DELIVERED_PASSENGER
N_STEP_UPDATE = 2

# REINFORCE Agent config
REINFORCE_INTIIAL_COLLECT_STEPS = 0
REINFORCE_LOG_INTERVAL = 3
REINFORCE_NUM_EVAL_EPISODES = 3
REINFORCE_EVAL_INTERVAL = 15
REINFORCE_COLLECT_EPISODES_PER_ITERATION = 2
